{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mskbasha/Sentiment_analyis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2l0_FxR27H3"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv4XELgW2zPV"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import math\n",
        "import keras \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.nn import functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,Dense,MultiHeadAttention,Input,LayerNormalization,Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1c6acG929XE"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKJyvl7UzHnv",
        "outputId": "1cee5030-b514-4cda-f30f-9179b134bac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[                              ] \n",
            " \n",
            "[                              ] \n",
            " \n",
            "[#                             ] \n",
            " \n",
            "[#                             ] \n",
            " \n",
            "[#                             ] \n",
            " \n",
            "[##                            ] \n",
            " \n",
            "[##                            ] \n",
            " \n",
            "[##                            ] \n",
            " \n",
            "[##                            ] \n",
            " \n",
            "[###                           ] \n",
            " \n",
            "[###                           ] \n",
            " \n",
            "[###                           ] \n",
            " \n",
            "[####                          ] \n",
            " \n",
            "[####                          ] \n",
            " \n",
            "[####                          ] \n",
            " \n",
            "[####                          ] \n",
            " \n",
            "[#####                         ] \n",
            " \n",
            "[#####                         ] \n",
            " \n",
            "[#####                         ] \n",
            " \n",
            "[######                        ] \n",
            " \n",
            "[######                        ] \n",
            " \n",
            "[######                        ] \n",
            " \n",
            "[#######                       ] \n",
            " \n",
            "[#######                       ] \n",
            " \n",
            "[#######                       ] \n",
            " \n",
            "[########                      ] \n",
            " \n",
            "[########                      ] \n",
            " \n",
            "[########                      ] \n",
            " \n",
            "[########                      ] \n",
            " \n",
            "[#########                     ] \n",
            " \n",
            "[#########                     ] \n",
            " \n",
            "[#########                     ] \n",
            " \n",
            "[##########                    ] \n",
            " \n",
            "[##########                    ] \n",
            " \n",
            "[##########                    ] \n",
            " \n",
            "[##########                    ] \n",
            " \n",
            "[###########                   ] \n",
            " \n",
            "[###########                   ] \n",
            " \n",
            "[###########                   ] \n",
            " \n",
            "[############                  ] \n",
            " \n",
            "[############                  ] \n",
            " \n",
            "[############                  ] \n",
            " \n",
            "[#############                 ] \n",
            " \n",
            "[#############                 ] \n",
            " \n",
            "[#############                 ] \n",
            " \n",
            "[##############                ] \n",
            " \n",
            "[##############                ] \n",
            " \n",
            "[##############                ] \n",
            " \n",
            "[##############                ] \n",
            " \n",
            "[###############               ] \n",
            " \n",
            "[###############               ] \n",
            " \n",
            "[###############               ] \n",
            " \n",
            "[################              ] \n",
            " \n",
            "[################              ] \n",
            " \n",
            "[################              ] \n",
            " \n",
            "[################              ] \n",
            " \n",
            "[#################             ] \n",
            " \n",
            "[#################             ] \n",
            " \n",
            "[#################             ] \n",
            " \n",
            "[##################            ] \n",
            " \n",
            "[##################            ] \n",
            " \n",
            "[##################            ] \n",
            " \n",
            "[###################           ] \n",
            " \n",
            "[###################           ] \n",
            " \n",
            "[###################           ] \n",
            " \n",
            "[####################          ] \n",
            " \n",
            "[####################          ] \n",
            " \n",
            "[####################          ] \n",
            " \n",
            "[####################          ] \n",
            " \n",
            "[#####################         ] \n",
            " \n",
            "[#####################         ] \n",
            " \n",
            "[#####################         ] \n",
            " \n",
            "[######################        ] \n",
            " \n",
            "[######################        ] \n",
            " \n",
            "[######################        ] \n",
            " \n",
            "[######################        ] \n",
            " \n",
            "[#######################       ] \n",
            " \n",
            "[#######################       ] \n",
            " \n",
            "[#######################       ] \n",
            " \n",
            "[########################      ] \n",
            " \n",
            "[########################      ] \n",
            " \n",
            "[########################      ] \n",
            " \n",
            "[#########################     ] \n",
            " \n",
            "[#########################     ] \n",
            " \n",
            "[#########################     ] \n",
            " \n",
            "[##########################    ] \n",
            " \n",
            "[##########################    ] \n",
            " \n",
            "[##########################    ] \n",
            " \n",
            "[##########################    ] \n",
            " \n",
            "[###########################   ] \n",
            " \n",
            "[###########################   ] \n",
            " \n",
            "[###########################   ] \n",
            " \n",
            "[############################  ] \n",
            " \n",
            "[############################  ] \n",
            " \n",
            "[############################  ] \n",
            " \n",
            "[############################  ] \n",
            " \n",
            "[############################# ] \n",
            " \n",
            "[############################# ] \n",
            " \n",
            "[############################# ] \n",
            " \n",
            "[##############################] \n",
            " \n"
          ]
        }
      ],
      "source": [
        "from progressbar import progressbar\n",
        "import time \n",
        "pb = progressbar(0.1,30,'#','')\n",
        "for i in range(100):\n",
        "    time.sleep(0.1)\n",
        "    pb.print(i,100,error =i**2 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KsSFsHvECMws"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(\"/content/drive/MyDrive/Chrome OS/Coding data/archive.zip\",'r') as f:\n",
        "    f.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8QOklH1C85Jt"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/train.csv\",encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "awy78rTM9Dm1",
        "outputId": "67f6ff54-0d3b-4537-9b7e-ac34271b5820"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d187cbd4-16a1-4291-ad3c-b9553ef3ca4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d187cbd4-16a1-4291-ad3c-b9553ef3ca4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d187cbd4-16a1-4291-ad3c-b9553ef3ca4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d187cbd4-16a1-4291-ad3c-b9553ef3ca4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       textID                                            text  \\\n",
              "0  cb774db0d1             I`d have responded, if I were going   \n",
              "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                       my boss is bullying me...   \n",
              "3  9642c003ef                  what interview! leave me alone   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
              "0  Afghanistan          38928346         652860.0               60  \n",
              "1      Albania           2877797          27400.0              105  \n",
              "2      Algeria          43851044        2381740.0               18  \n",
              "3      Andorra             77265            470.0              164  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eMr0UMpMxA4s"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5naE9HPlw0Q9"
      },
      "outputs": [],
      "source": [
        "unique_chars = set(' '.join(data.text.dropna()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kuiLYhQhy9vG",
        "outputId": "24535ef6-b599-4a7a-857f-c42598067104"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.text.apply(lambda x:len(x)).plot.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TUsIP4iOzQxq"
      },
      "outputs": [],
      "source": [
        "chars = {char:ind+1 for ind,char in enumerate(unique_chars)}\n",
        "index = {ind+1:char for ind,char in enumerate(unique_chars)}\n",
        "\n",
        "data['embeddings'] = data.text.fillna('').apply(lambda x:[chars[i] for i in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sTWdIlq2xLPz"
      },
      "outputs": [],
      "source": [
        "padded_sequences = pad_sequences(data['embeddings'], maxlen=100, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "--iuvjxH0Dr7",
        "outputId": "64b6c22e-da14-4a73-8b4c-4968d520b6df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27480, 100)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ROc29oOQ0LSs",
        "outputId": "9a9a4f11-fcbe-410b-f82e-2237056c57fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((27480, 100), (27480,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 400x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.sentiment.value_counts().plot.barh(figsize = (4,2))\n",
        "padded_sequences.shape,data.sentiment.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E4WgPA2v0mLc"
      },
      "outputs": [],
      "source": [
        "y = pd.get_dummies(data.sentiment)\n",
        "x = padded_sequences\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aJrq-_Bw1L1Q",
        "outputId": "28005228-2787-4754-da14-c08c04eb14f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((27480, 100), (27480, 3))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape,y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oeU-KRQ-HxCL",
        "outputId": "3c46ea1c-2f2d-47f2-c392-4cca4577f984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(unique_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CbUrnd_cDRZ7"
      },
      "outputs": [],
      "source": [
        "!pip install keras_nlp --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-7cGxPKXL5I",
        "outputId": "e3a9d8d7-32e6-4631-b909-caefea64028a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20610, 100)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl235cP-1Yu0"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, MultiHeadAttention, LayerNormalization, Flatten,GlobalMaxPooling1D\n",
        "import keras_nlp\n",
        "text_size = 100\n",
        "embedding_size = 500\n",
        "inputlayer = Input(shape=(text_size,))\n",
        "output = Embedding(len(unique_chars) + 1, embedding_size, mask_zero=True)(inputlayer)\n",
        "output = keras_nlp.layers.PositionEmbedding(\n",
        "    embedding_size, initializer=\"glorot_uniform\"\n",
        ")(output)\n",
        "for i in range(50):\n",
        "  output = keras_nlp.layers.TransformerEncoder(\n",
        "      intermediate_dim=1000, num_heads=8)(output)\n",
        "output = GlobalMaxPooling1D()(output) \n",
        "output = Dense(3,activation='softmax')(output)\n",
        "\n",
        "model = keras.models.Model(inputs=inputlayer, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Vt_EODcdg2"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train,y_train,epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFi8u5KOHwaz",
        "outputId": "d3367bc9-a49c-4a5f-a658-204db04e1bbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       ...,\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(y_test.values,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioAJYRvfHfp3",
        "outputId": "fe446c71-77d8-4121-d2de-fa900a5f32c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "215/215 [==============================] - 6s 30ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.18933472294597883"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = np.argmax(model.predict(x_test),axis=1)\n",
        "f1_score(y_pred,np.argmax(y_test.values,axis=1),average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiLutKZXQQE1"
      },
      "outputs": [],
      "source": [
        "dx_train = torch.tensor(x_train)\n",
        "y_train = torch.tensor(y_train.to_numpy())\n",
        "y_train = torch.argmax(y_train,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo1SLgJFzX0r"
      },
      "outputs": [],
      "source": [
        "x_test = torch.tensor(x_test)\n",
        "y_test = torch.tensor(y_test.to_numpy())\n",
        "y_test = torch.argmax(y_test,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGP7TVGDV10i"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "class EncoderBlock(torch.nn.Module):\n",
        "    def __init__(self,no_heads,seq_length,Embedding_dim):\n",
        "        super().__init__()\n",
        "        assert Embedding_dim%no_heads ==0\n",
        "        self.FF = torch.nn.Linear(Embedding_dim,Embedding_dim,bias = False)\n",
        "        self.MHA = torch.nn.MultiheadAttention(Embedding_dim,no_heads,dropout=0.01,batch_first=True)\n",
        "        self.ffn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(Embedding_dim, int(1.5*Embedding_dim)),\n",
        "            torch.nn.ReLU(inplace=False),\n",
        "            torch.nn.Linear(int(1.5*Embedding_dim), Embedding_dim)\n",
        "        )\n",
        "        self.normE = torch.nn.LayerNorm(Embedding_dim)\n",
        "        self.normF = torch.nn.LayerNorm(Embedding_dim)\n",
        "        self.PE = PositionalEncoding(Embedding_dim)\n",
        "    def forward(self,x,key_padding_mask=None,attn_mask=None):\n",
        "        x = self.PE(x.permute(1,0,2))\n",
        "        x = x.permute(1,0,2)\n",
        "        q = self.FF(x)\n",
        "        k = self.FF(x)\n",
        "        v = self.FF(x)\n",
        "        output = self.MHA(q,k,v,key_padding_mask,attn_mask)[0]+x\n",
        "        output1 = self.normE(output)\n",
        "        output = self.ffn(output1)\n",
        "        output = output+output1\n",
        "        output = self.normF(output)\n",
        "        return output\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self,no_blocks,no_heads,seq_length,Embedding_dim,unique_chars):\n",
        "        super().__init__()\n",
        "        self.Emb = torch.nn.Embedding(len(unique_chars)+1,embedding_dim=Embedding_dim,padding_idx=0)\n",
        "        self.blocks = torch.nn.ModuleList([EncoderBlock(no_heads,seq_length,Embedding_dim) for _ in range(no_blocks)])\n",
        "        self.Flatten = torch.nn.Flatten()\n",
        "        self.linear = torch.nn.Linear(Embedding_dim*seq_length,3,bias=True)\n",
        "    def forward(self,x):\n",
        "        mask = (x==0)\n",
        "        x = self.Emb(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x,mask)\n",
        "        x = self.Flatten(x)\n",
        "        return self.linear(x)\n",
        "model = Encoder(30,10,100,130,unique_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FUwbjUEvXKU",
        "outputId": "d3ec5e93-cf06-4eb1-e8f8-e6efa990a3d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20610, 100])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gBrIpwvNPdM",
        "outputId": "088c739a-bb0e-4104-c7ea-7c886d06b5ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------+------------+\n",
            "|            Modules            | Parameters |\n",
            "+-------------------------------+------------+\n",
            "|           Emb.weight          |   13520    |\n",
            "|       blocks.0.FF.weight      |   16900    |\n",
            "|  blocks.0.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.0.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.0.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.0.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.0.ffn.0.weight     |   25350    |\n",
            "|      blocks.0.ffn.0.bias      |    195     |\n",
            "|     blocks.0.ffn.2.weight     |   25350    |\n",
            "|      blocks.0.ffn.2.bias      |    130     |\n",
            "|     blocks.0.normE.weight     |    130     |\n",
            "|      blocks.0.normE.bias      |    130     |\n",
            "|     blocks.0.normF.weight     |    130     |\n",
            "|      blocks.0.normF.bias      |    130     |\n",
            "|       blocks.1.FF.weight      |   16900    |\n",
            "|  blocks.1.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.1.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.1.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.1.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.1.ffn.0.weight     |   25350    |\n",
            "|      blocks.1.ffn.0.bias      |    195     |\n",
            "|     blocks.1.ffn.2.weight     |   25350    |\n",
            "|      blocks.1.ffn.2.bias      |    130     |\n",
            "|     blocks.1.normE.weight     |    130     |\n",
            "|      blocks.1.normE.bias      |    130     |\n",
            "|     blocks.1.normF.weight     |    130     |\n",
            "|      blocks.1.normF.bias      |    130     |\n",
            "|       blocks.2.FF.weight      |   16900    |\n",
            "|  blocks.2.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.2.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.2.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.2.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.2.ffn.0.weight     |   25350    |\n",
            "|      blocks.2.ffn.0.bias      |    195     |\n",
            "|     blocks.2.ffn.2.weight     |   25350    |\n",
            "|      blocks.2.ffn.2.bias      |    130     |\n",
            "|     blocks.2.normE.weight     |    130     |\n",
            "|      blocks.2.normE.bias      |    130     |\n",
            "|     blocks.2.normF.weight     |    130     |\n",
            "|      blocks.2.normF.bias      |    130     |\n",
            "|       blocks.3.FF.weight      |   16900    |\n",
            "|  blocks.3.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.3.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.3.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.3.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.3.ffn.0.weight     |   25350    |\n",
            "|      blocks.3.ffn.0.bias      |    195     |\n",
            "|     blocks.3.ffn.2.weight     |   25350    |\n",
            "|      blocks.3.ffn.2.bias      |    130     |\n",
            "|     blocks.3.normE.weight     |    130     |\n",
            "|      blocks.3.normE.bias      |    130     |\n",
            "|     blocks.3.normF.weight     |    130     |\n",
            "|      blocks.3.normF.bias      |    130     |\n",
            "|       blocks.4.FF.weight      |   16900    |\n",
            "|  blocks.4.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.4.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.4.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.4.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.4.ffn.0.weight     |   25350    |\n",
            "|      blocks.4.ffn.0.bias      |    195     |\n",
            "|     blocks.4.ffn.2.weight     |   25350    |\n",
            "|      blocks.4.ffn.2.bias      |    130     |\n",
            "|     blocks.4.normE.weight     |    130     |\n",
            "|      blocks.4.normE.bias      |    130     |\n",
            "|     blocks.4.normF.weight     |    130     |\n",
            "|      blocks.4.normF.bias      |    130     |\n",
            "|       blocks.5.FF.weight      |   16900    |\n",
            "|  blocks.5.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.5.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.5.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.5.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.5.ffn.0.weight     |   25350    |\n",
            "|      blocks.5.ffn.0.bias      |    195     |\n",
            "|     blocks.5.ffn.2.weight     |   25350    |\n",
            "|      blocks.5.ffn.2.bias      |    130     |\n",
            "|     blocks.5.normE.weight     |    130     |\n",
            "|      blocks.5.normE.bias      |    130     |\n",
            "|     blocks.5.normF.weight     |    130     |\n",
            "|      blocks.5.normF.bias      |    130     |\n",
            "|       blocks.6.FF.weight      |   16900    |\n",
            "|  blocks.6.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.6.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.6.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.6.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.6.ffn.0.weight     |   25350    |\n",
            "|      blocks.6.ffn.0.bias      |    195     |\n",
            "|     blocks.6.ffn.2.weight     |   25350    |\n",
            "|      blocks.6.ffn.2.bias      |    130     |\n",
            "|     blocks.6.normE.weight     |    130     |\n",
            "|      blocks.6.normE.bias      |    130     |\n",
            "|     blocks.6.normF.weight     |    130     |\n",
            "|      blocks.6.normF.bias      |    130     |\n",
            "|       blocks.7.FF.weight      |   16900    |\n",
            "|  blocks.7.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.7.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.7.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.7.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.7.ffn.0.weight     |   25350    |\n",
            "|      blocks.7.ffn.0.bias      |    195     |\n",
            "|     blocks.7.ffn.2.weight     |   25350    |\n",
            "|      blocks.7.ffn.2.bias      |    130     |\n",
            "|     blocks.7.normE.weight     |    130     |\n",
            "|      blocks.7.normE.bias      |    130     |\n",
            "|     blocks.7.normF.weight     |    130     |\n",
            "|      blocks.7.normF.bias      |    130     |\n",
            "|       blocks.8.FF.weight      |   16900    |\n",
            "|  blocks.8.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.8.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.8.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.8.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.8.ffn.0.weight     |   25350    |\n",
            "|      blocks.8.ffn.0.bias      |    195     |\n",
            "|     blocks.8.ffn.2.weight     |   25350    |\n",
            "|      blocks.8.ffn.2.bias      |    130     |\n",
            "|     blocks.8.normE.weight     |    130     |\n",
            "|      blocks.8.normE.bias      |    130     |\n",
            "|     blocks.8.normF.weight     |    130     |\n",
            "|      blocks.8.normF.bias      |    130     |\n",
            "|       blocks.9.FF.weight      |   16900    |\n",
            "|  blocks.9.MHA.in_proj_weight  |   50700    |\n",
            "|   blocks.9.MHA.in_proj_bias   |    390     |\n",
            "|  blocks.9.MHA.out_proj.weight |   16900    |\n",
            "|   blocks.9.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.9.ffn.0.weight     |   25350    |\n",
            "|      blocks.9.ffn.0.bias      |    195     |\n",
            "|     blocks.9.ffn.2.weight     |   25350    |\n",
            "|      blocks.9.ffn.2.bias      |    130     |\n",
            "|     blocks.9.normE.weight     |    130     |\n",
            "|      blocks.9.normE.bias      |    130     |\n",
            "|     blocks.9.normF.weight     |    130     |\n",
            "|      blocks.9.normF.bias      |    130     |\n",
            "|      blocks.10.FF.weight      |   16900    |\n",
            "|  blocks.10.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.10.MHA.in_proj_bias  |    390     |\n",
            "| blocks.10.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.10.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.10.ffn.0.weight    |   25350    |\n",
            "|      blocks.10.ffn.0.bias     |    195     |\n",
            "|     blocks.10.ffn.2.weight    |   25350    |\n",
            "|      blocks.10.ffn.2.bias     |    130     |\n",
            "|     blocks.10.normE.weight    |    130     |\n",
            "|      blocks.10.normE.bias     |    130     |\n",
            "|     blocks.10.normF.weight    |    130     |\n",
            "|      blocks.10.normF.bias     |    130     |\n",
            "|      blocks.11.FF.weight      |   16900    |\n",
            "|  blocks.11.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.11.MHA.in_proj_bias  |    390     |\n",
            "| blocks.11.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.11.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.11.ffn.0.weight    |   25350    |\n",
            "|      blocks.11.ffn.0.bias     |    195     |\n",
            "|     blocks.11.ffn.2.weight    |   25350    |\n",
            "|      blocks.11.ffn.2.bias     |    130     |\n",
            "|     blocks.11.normE.weight    |    130     |\n",
            "|      blocks.11.normE.bias     |    130     |\n",
            "|     blocks.11.normF.weight    |    130     |\n",
            "|      blocks.11.normF.bias     |    130     |\n",
            "|      blocks.12.FF.weight      |   16900    |\n",
            "|  blocks.12.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.12.MHA.in_proj_bias  |    390     |\n",
            "| blocks.12.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.12.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.12.ffn.0.weight    |   25350    |\n",
            "|      blocks.12.ffn.0.bias     |    195     |\n",
            "|     blocks.12.ffn.2.weight    |   25350    |\n",
            "|      blocks.12.ffn.2.bias     |    130     |\n",
            "|     blocks.12.normE.weight    |    130     |\n",
            "|      blocks.12.normE.bias     |    130     |\n",
            "|     blocks.12.normF.weight    |    130     |\n",
            "|      blocks.12.normF.bias     |    130     |\n",
            "|      blocks.13.FF.weight      |   16900    |\n",
            "|  blocks.13.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.13.MHA.in_proj_bias  |    390     |\n",
            "| blocks.13.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.13.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.13.ffn.0.weight    |   25350    |\n",
            "|      blocks.13.ffn.0.bias     |    195     |\n",
            "|     blocks.13.ffn.2.weight    |   25350    |\n",
            "|      blocks.13.ffn.2.bias     |    130     |\n",
            "|     blocks.13.normE.weight    |    130     |\n",
            "|      blocks.13.normE.bias     |    130     |\n",
            "|     blocks.13.normF.weight    |    130     |\n",
            "|      blocks.13.normF.bias     |    130     |\n",
            "|      blocks.14.FF.weight      |   16900    |\n",
            "|  blocks.14.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.14.MHA.in_proj_bias  |    390     |\n",
            "| blocks.14.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.14.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.14.ffn.0.weight    |   25350    |\n",
            "|      blocks.14.ffn.0.bias     |    195     |\n",
            "|     blocks.14.ffn.2.weight    |   25350    |\n",
            "|      blocks.14.ffn.2.bias     |    130     |\n",
            "|     blocks.14.normE.weight    |    130     |\n",
            "|      blocks.14.normE.bias     |    130     |\n",
            "|     blocks.14.normF.weight    |    130     |\n",
            "|      blocks.14.normF.bias     |    130     |\n",
            "|      blocks.15.FF.weight      |   16900    |\n",
            "|  blocks.15.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.15.MHA.in_proj_bias  |    390     |\n",
            "| blocks.15.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.15.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.15.ffn.0.weight    |   25350    |\n",
            "|      blocks.15.ffn.0.bias     |    195     |\n",
            "|     blocks.15.ffn.2.weight    |   25350    |\n",
            "|      blocks.15.ffn.2.bias     |    130     |\n",
            "|     blocks.15.normE.weight    |    130     |\n",
            "|      blocks.15.normE.bias     |    130     |\n",
            "|     blocks.15.normF.weight    |    130     |\n",
            "|      blocks.15.normF.bias     |    130     |\n",
            "|      blocks.16.FF.weight      |   16900    |\n",
            "|  blocks.16.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.16.MHA.in_proj_bias  |    390     |\n",
            "| blocks.16.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.16.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.16.ffn.0.weight    |   25350    |\n",
            "|      blocks.16.ffn.0.bias     |    195     |\n",
            "|     blocks.16.ffn.2.weight    |   25350    |\n",
            "|      blocks.16.ffn.2.bias     |    130     |\n",
            "|     blocks.16.normE.weight    |    130     |\n",
            "|      blocks.16.normE.bias     |    130     |\n",
            "|     blocks.16.normF.weight    |    130     |\n",
            "|      blocks.16.normF.bias     |    130     |\n",
            "|      blocks.17.FF.weight      |   16900    |\n",
            "|  blocks.17.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.17.MHA.in_proj_bias  |    390     |\n",
            "| blocks.17.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.17.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.17.ffn.0.weight    |   25350    |\n",
            "|      blocks.17.ffn.0.bias     |    195     |\n",
            "|     blocks.17.ffn.2.weight    |   25350    |\n",
            "|      blocks.17.ffn.2.bias     |    130     |\n",
            "|     blocks.17.normE.weight    |    130     |\n",
            "|      blocks.17.normE.bias     |    130     |\n",
            "|     blocks.17.normF.weight    |    130     |\n",
            "|      blocks.17.normF.bias     |    130     |\n",
            "|      blocks.18.FF.weight      |   16900    |\n",
            "|  blocks.18.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.18.MHA.in_proj_bias  |    390     |\n",
            "| blocks.18.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.18.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.18.ffn.0.weight    |   25350    |\n",
            "|      blocks.18.ffn.0.bias     |    195     |\n",
            "|     blocks.18.ffn.2.weight    |   25350    |\n",
            "|      blocks.18.ffn.2.bias     |    130     |\n",
            "|     blocks.18.normE.weight    |    130     |\n",
            "|      blocks.18.normE.bias     |    130     |\n",
            "|     blocks.18.normF.weight    |    130     |\n",
            "|      blocks.18.normF.bias     |    130     |\n",
            "|      blocks.19.FF.weight      |   16900    |\n",
            "|  blocks.19.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.19.MHA.in_proj_bias  |    390     |\n",
            "| blocks.19.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.19.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.19.ffn.0.weight    |   25350    |\n",
            "|      blocks.19.ffn.0.bias     |    195     |\n",
            "|     blocks.19.ffn.2.weight    |   25350    |\n",
            "|      blocks.19.ffn.2.bias     |    130     |\n",
            "|     blocks.19.normE.weight    |    130     |\n",
            "|      blocks.19.normE.bias     |    130     |\n",
            "|     blocks.19.normF.weight    |    130     |\n",
            "|      blocks.19.normF.bias     |    130     |\n",
            "|      blocks.20.FF.weight      |   16900    |\n",
            "|  blocks.20.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.20.MHA.in_proj_bias  |    390     |\n",
            "| blocks.20.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.20.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.20.ffn.0.weight    |   25350    |\n",
            "|      blocks.20.ffn.0.bias     |    195     |\n",
            "|     blocks.20.ffn.2.weight    |   25350    |\n",
            "|      blocks.20.ffn.2.bias     |    130     |\n",
            "|     blocks.20.normE.weight    |    130     |\n",
            "|      blocks.20.normE.bias     |    130     |\n",
            "|     blocks.20.normF.weight    |    130     |\n",
            "|      blocks.20.normF.bias     |    130     |\n",
            "|      blocks.21.FF.weight      |   16900    |\n",
            "|  blocks.21.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.21.MHA.in_proj_bias  |    390     |\n",
            "| blocks.21.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.21.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.21.ffn.0.weight    |   25350    |\n",
            "|      blocks.21.ffn.0.bias     |    195     |\n",
            "|     blocks.21.ffn.2.weight    |   25350    |\n",
            "|      blocks.21.ffn.2.bias     |    130     |\n",
            "|     blocks.21.normE.weight    |    130     |\n",
            "|      blocks.21.normE.bias     |    130     |\n",
            "|     blocks.21.normF.weight    |    130     |\n",
            "|      blocks.21.normF.bias     |    130     |\n",
            "|      blocks.22.FF.weight      |   16900    |\n",
            "|  blocks.22.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.22.MHA.in_proj_bias  |    390     |\n",
            "| blocks.22.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.22.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.22.ffn.0.weight    |   25350    |\n",
            "|      blocks.22.ffn.0.bias     |    195     |\n",
            "|     blocks.22.ffn.2.weight    |   25350    |\n",
            "|      blocks.22.ffn.2.bias     |    130     |\n",
            "|     blocks.22.normE.weight    |    130     |\n",
            "|      blocks.22.normE.bias     |    130     |\n",
            "|     blocks.22.normF.weight    |    130     |\n",
            "|      blocks.22.normF.bias     |    130     |\n",
            "|      blocks.23.FF.weight      |   16900    |\n",
            "|  blocks.23.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.23.MHA.in_proj_bias  |    390     |\n",
            "| blocks.23.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.23.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.23.ffn.0.weight    |   25350    |\n",
            "|      blocks.23.ffn.0.bias     |    195     |\n",
            "|     blocks.23.ffn.2.weight    |   25350    |\n",
            "|      blocks.23.ffn.2.bias     |    130     |\n",
            "|     blocks.23.normE.weight    |    130     |\n",
            "|      blocks.23.normE.bias     |    130     |\n",
            "|     blocks.23.normF.weight    |    130     |\n",
            "|      blocks.23.normF.bias     |    130     |\n",
            "|      blocks.24.FF.weight      |   16900    |\n",
            "|  blocks.24.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.24.MHA.in_proj_bias  |    390     |\n",
            "| blocks.24.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.24.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.24.ffn.0.weight    |   25350    |\n",
            "|      blocks.24.ffn.0.bias     |    195     |\n",
            "|     blocks.24.ffn.2.weight    |   25350    |\n",
            "|      blocks.24.ffn.2.bias     |    130     |\n",
            "|     blocks.24.normE.weight    |    130     |\n",
            "|      blocks.24.normE.bias     |    130     |\n",
            "|     blocks.24.normF.weight    |    130     |\n",
            "|      blocks.24.normF.bias     |    130     |\n",
            "|      blocks.25.FF.weight      |   16900    |\n",
            "|  blocks.25.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.25.MHA.in_proj_bias  |    390     |\n",
            "| blocks.25.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.25.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.25.ffn.0.weight    |   25350    |\n",
            "|      blocks.25.ffn.0.bias     |    195     |\n",
            "|     blocks.25.ffn.2.weight    |   25350    |\n",
            "|      blocks.25.ffn.2.bias     |    130     |\n",
            "|     blocks.25.normE.weight    |    130     |\n",
            "|      blocks.25.normE.bias     |    130     |\n",
            "|     blocks.25.normF.weight    |    130     |\n",
            "|      blocks.25.normF.bias     |    130     |\n",
            "|      blocks.26.FF.weight      |   16900    |\n",
            "|  blocks.26.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.26.MHA.in_proj_bias  |    390     |\n",
            "| blocks.26.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.26.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.26.ffn.0.weight    |   25350    |\n",
            "|      blocks.26.ffn.0.bias     |    195     |\n",
            "|     blocks.26.ffn.2.weight    |   25350    |\n",
            "|      blocks.26.ffn.2.bias     |    130     |\n",
            "|     blocks.26.normE.weight    |    130     |\n",
            "|      blocks.26.normE.bias     |    130     |\n",
            "|     blocks.26.normF.weight    |    130     |\n",
            "|      blocks.26.normF.bias     |    130     |\n",
            "|      blocks.27.FF.weight      |   16900    |\n",
            "|  blocks.27.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.27.MHA.in_proj_bias  |    390     |\n",
            "| blocks.27.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.27.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.27.ffn.0.weight    |   25350    |\n",
            "|      blocks.27.ffn.0.bias     |    195     |\n",
            "|     blocks.27.ffn.2.weight    |   25350    |\n",
            "|      blocks.27.ffn.2.bias     |    130     |\n",
            "|     blocks.27.normE.weight    |    130     |\n",
            "|      blocks.27.normE.bias     |    130     |\n",
            "|     blocks.27.normF.weight    |    130     |\n",
            "|      blocks.27.normF.bias     |    130     |\n",
            "|      blocks.28.FF.weight      |   16900    |\n",
            "|  blocks.28.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.28.MHA.in_proj_bias  |    390     |\n",
            "| blocks.28.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.28.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.28.ffn.0.weight    |   25350    |\n",
            "|      blocks.28.ffn.0.bias     |    195     |\n",
            "|     blocks.28.ffn.2.weight    |   25350    |\n",
            "|      blocks.28.ffn.2.bias     |    130     |\n",
            "|     blocks.28.normE.weight    |    130     |\n",
            "|      blocks.28.normE.bias     |    130     |\n",
            "|     blocks.28.normF.weight    |    130     |\n",
            "|      blocks.28.normF.bias     |    130     |\n",
            "|      blocks.29.FF.weight      |   16900    |\n",
            "|  blocks.29.MHA.in_proj_weight |   50700    |\n",
            "|   blocks.29.MHA.in_proj_bias  |    390     |\n",
            "| blocks.29.MHA.out_proj.weight |   16900    |\n",
            "|  blocks.29.MHA.out_proj.bias  |    130     |\n",
            "|     blocks.29.ffn.0.weight    |   25350    |\n",
            "|      blocks.29.ffn.0.bias     |    195     |\n",
            "|     blocks.29.ffn.2.weight    |   25350    |\n",
            "|      blocks.29.ffn.2.bias     |    130     |\n",
            "|     blocks.29.normE.weight    |    130     |\n",
            "|      blocks.29.normE.bias     |    130     |\n",
            "|     blocks.29.normF.weight    |    130     |\n",
            "|      blocks.29.normF.bias     |    130     |\n",
            "|         linear.weight         |   39000    |\n",
            "|          linear.bias          |     3      |\n",
            "+-------------------------------+------------+\n",
            "Total Trainable Params: 4149473\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4149473"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: \n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params+=params\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYK3_OYyz3Tx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train = TensorDataset(x_train, y_train)\n",
        "test =  TensorDataset(x_test, y_test)\n",
        "batch_size = 32\n",
        "train_dataset, test_dataset = DataLoader(train,batch_size=batch_size, shuffle=True),DataLoader(test,batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA-pmAesEK8R",
        "outputId": "7138ec36-0b79-4341-d7e6-3b223304b424"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (Emb): Embedding(104, 130, padding_idx=0)\n",
              "  (blocks): ModuleList(\n",
              "    (0-29): 30 x EncoderBlock(\n",
              "      (FF): Linear(in_features=130, out_features=130, bias=False)\n",
              "      (MHA): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=130, out_features=130, bias=True)\n",
              "      )\n",
              "      (ffn): Sequential(\n",
              "        (0): Linear(in_features=130, out_features=195, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=195, out_features=130, bias=True)\n",
              "      )\n",
              "      (normE): LayerNorm((130,), eps=1e-05, elementwise_affine=True)\n",
              "      (normF): LayerNorm((130,), eps=1e-05, elementwise_affine=True)\n",
              "      (PE): PositionalEncoding(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear): Linear(in_features=13000, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFG4JQN9EI-T",
        "outputId": "68b7c4ed-9057-493a-8322-204a5bb76b46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.23173182373182374"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict(test_dataset,batch_size):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in test_dataset:\n",
        "            inputs = inputs.cuda()\n",
        "            y_pred.append(torch.argmax(model(inputs),axis=1))\n",
        "            y_true.append(labels)\n",
        "        y_pred,y_true = torch.cat(y_pred),torch.cat(y_true)\n",
        "        return f1_score(y_true.cpu(),y_pred.cpu(),average='macro')\n",
        "predict(test_dataset,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjab6jUYrWUY",
        "outputId": "859673d5-ae37-4300-9042-dd2117b848bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[--------------------------------------------------------------->.....................................] \n",
            " \n",
            " 1.08 for 0 epoch f1score = 0.23\n"
          ]
        }
      ],
      "source": [
        "from progressbar import progressbar\n",
        "pb = progressbar(1)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "full_loss = 0\n",
        "with torch.autograd.set_detect_anomaly(True):\n",
        "    for epoch in range(10):\n",
        "        score = predict(test_dataset,32)   \n",
        "        for i,(inputs,labels) in enumerate(train_dataset):\n",
        "            optimizer.zero_grad()\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            full_loss+=loss.item()\n",
        "            pb.print(i,644,f\"\\n {round(loss.item(),2)} for {epoch} epoch f1score = {round(score,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6SeyxuSElbd",
        "outputId": "946f3ffa-66a1-44cb-90fb-8111e3c9c7c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (Emb): Embedding(104, 100, padding_idx=0)\n",
              "  (blocks): ModuleList(\n",
              "    (0-9): 10 x EncoderBlock(\n",
              "      (FF): Linear(in_features=100, out_features=100, bias=False)\n",
              "      (MHA): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
              "      )\n",
              "      (ffn): Sequential(\n",
              "        (0): Linear(in_features=100, out_features=150, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Linear(in_features=150, out_features=100, bias=True)\n",
              "      )\n",
              "      (normE): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "      (normF): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear): Linear(in_features=10000, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrF9Z2S8ueOl",
        "outputId": "d9fe97cf-f4f1-456c-ed82-90deaa521142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2994561417260664"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict(batch_size):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in test_dataset:\n",
        "            inputs = inputs.cuda()\n",
        "            y_pred.append(torch.argmax(model(inputs),axis=1))\n",
        "            y_true.append(labels)\n",
        "        y_pred,y_true = torch.cat(y_pred),torch.cat(y_true)\n",
        "        return f1_score(y_true.cpu(),y_pred.cpu(),average='macro')\n",
        "predict(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tbc9x6Kzgl8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTYzyb0d71oe",
        "outputId": "874088f1-a772-4955-e8e9-4a650b11f6a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.29993168739944576"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjdVrXnLTFmw",
        "outputId": "de280ad0-4697-420f-f3f0-2fe6b611edb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.8592,  0.3960,  0.3329,  0.5369,  0.4732],\n",
              "         [-1.9554, -0.3758,  0.9111,  0.4702, -1.3886],\n",
              "         [-1.8866, -1.0000,  1.0224,  0.0056,  0.1627]]),\n",
              " tensor([4, 3, 4]),\n",
              " tensor(1.4614))"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of target with class indices\n",
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.tensor([[ 0.8592,  0.3960,  0.3329,  0.5369,  0.4732],\n",
        "         [-1.9554, -0.3758,  0.9111,  0.4702, -1.3886],\n",
        "         [-1.8866, -1.0000,  1.0224,  0.0056,  0.1627]])\n",
        "target = torch.tensor([4,3,4])\n",
        "output = loss(input, target)\n",
        "input,target,output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUNB7BHF-NMV",
        "outputId": "6546e918-b237-4b69-bb6c-b098cf4e33ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-4.384077237228478"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = 0\n",
        "l = 4,3,4\n",
        "for ind,i in enumerate(torch.nn.functional.softmax(input,dim=1)):\n",
        "    k+=math.log(i[l[ind]])\n",
        "k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I91B3cAgly1c",
        "outputId": "fbc04744-4da3-47a3-dae4-0aecc6c83c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manually computed loss: tensor(4.3841)\n",
            "Loss using CrossEntropyLoss: tensor(1.4614)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Predicted class scores (logits)\n",
        "input = torch.tensor([[0.8592, 0.3960, 0.3329, 0.5369, 0.4732],\n",
        "                     [-1.9554, -0.3758, 0.9111, 0.4702, -1.3886],\n",
        "                     [-1.8866, -1.0000, 1.0224, 0.0056, 0.1627]])\n",
        "\n",
        "# Target class labels\n",
        "target = torch.tensor([4, 3, 4])\n",
        "\n",
        "# Calculate the softmax probabilities\n",
        "probabilities = torch.softmax(input, dim=1)\n",
        "\n",
        "# Calculate the manually computed loss\n",
        "manually_computed_loss = -torch.log(probabilities[range(len(target)), target]).sum()\n",
        "\n",
        "# Calculate the loss using CrossEntropyLoss\n",
        "output = loss(input, target)\n",
        "\n",
        "print(\"Manually computed loss:\", manually_computed_loss)\n",
        "print(\"Loss using CrossEntropyLoss:\", output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqvxns-H-0WK",
        "outputId": "ecf9f7cc-6ed4-4bbc-ad04-ecc01e847694"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 0, 1, 2, 0],\n",
              "        [3, 0, 5, 3, 0, 5],\n",
              "        [6, 0, 1, 6, 0, 1],\n",
              "        [0, 1, 2, 0, 1, 2]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.tensor([[\n",
        "    [1,2,0],\n",
        "    [3,0,5],\n",
        "    [6,0,1],\n",
        "    [0,1,2],\n",
        "],\n",
        "[\n",
        "    [1,2,0],\n",
        "    [3,0,5],\n",
        "    [6,0,1],\n",
        "    [0,1,2],\n",
        "]])\n",
        "torch.cat([k[0,:,:],k[1,:,:]],dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfRHRiS5QcYy",
        "outputId": "e32dbff7-2976-42f2-9e6a-de35ff9699d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 3, 3])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.normal(0,1,size=(4,3,3,3)).masked_fill(k[:,None,None,:]==0,float('-inf')).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvzYQdg1QqUr",
        "outputId": "a080420f-1363-4623-812c-32cd4107cf26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 5, 10, 5])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.normal(0,1,size=(10,5,10,10)),torch.normal(0,1,size = (10,5,10,5))).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUkw1wHLSQ45",
        "outputId": "01f4f0fb-1967-47cc-91bf-ffcab6e9a98c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 4, 5]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([[1,2,3],[3,4,5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbl3gyBxT9IP",
        "outputId": "a6930485-770d-4e9b-a284-f42f7055a9fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 3],\n",
              "        [4, 5]])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([[1,2,3],[3,4,5]]).reshape(3,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHmjmMaaT_Mc"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import MultiHeadAttention,LayerNormalization,Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "def encoder_block(input_tensor,emb_dim,num_heads):\n",
        "    q, k, v= Dense(emb_dim)(input_tensor), Dense(emb_dim)(input_tensor), Dense(emb_dim)(input_tensor)\n",
        "    output = MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim)(q,k,v)\n",
        "    output = LayerNormalization()(output)\n",
        "    res = input_tensor+output\n",
        "    output = Dense(emb_dim)(res)\n",
        "    output = output+res\n",
        "    return q,k,v,output\n",
        "input_tensor = tf.keras.layers.Input((5,12))\n",
        "output = input_tensor\n",
        "for i in range(10): \n",
        "    q,k,v, output = encoder_block(output,12,2)\n",
        "\n",
        "model = keras.Model(inputs=input_tensor, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te-2lbfqf0Mm",
        "outputId": "5799124b-7de3-4f75-8106-e9e08072a6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(10, 5, 12)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = tf.random.normal((10,5,12),0,1)\n",
        "model.predict(k).shapex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NYU68Lgg4cp",
        "outputId": "07d111d7-fb8a-45e6-9186-2b14d817cebe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([10, 1])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import keras\n",
        "keras.layers.Dense(1)(tf.random.normal((10,10,),0,1)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYmXfxSkhc-T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1MrIbpGsnvgm5WeVTbsEt1f5ynpBODwOu",
      "authorship_tag": "ABX9TyNE8Z3POZLFkJ7+wWaJgC87",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}