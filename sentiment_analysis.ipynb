{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQBIWjcCZVXz2fpOL5DBZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mskbasha/Sentiment_analyis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "k2l0_FxR27H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import math\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "mv4XELgW2zPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Data"
      ],
      "metadata": {
        "id": "h1c6acG929XE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq7UI7ISkqna",
        "outputId": "43e35627-af8d-4f59-c69b-bb4970ec3bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0468,  0.1302, -0.1449,  0.1121,  0.0797, -0.1255],\n",
            "         [-0.0531,  0.1255, -0.1361,  0.1127,  0.0835, -0.1183],\n",
            "         [-0.0500,  0.1196, -0.1442,  0.1054,  0.0788, -0.1154],\n",
            "         [-0.0679,  0.1181, -0.1161,  0.1096,  0.0881, -0.1065],\n",
            "         [-0.0683,  0.1294, -0.1511,  0.1240,  0.0792, -0.1091]],\n",
            "\n",
            "        [[-0.1219,  0.2945, -0.1813,  0.2992,  0.1208, -0.1694],\n",
            "         [-0.1344,  0.1958, -0.1305,  0.2183,  0.1182, -0.0980],\n",
            "         [-0.0747,  0.2288, -0.1483,  0.2236,  0.1078, -0.1475],\n",
            "         [-0.1659,  0.3574, -0.2101,  0.3709,  0.1316, -0.1907],\n",
            "         [-0.1284,  0.1644, -0.1087,  0.1874,  0.1141, -0.0807]]],\n",
            "       grad_fn=<TransposeBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.9797,  1.7493, -1.7915,  0.8403,  0.0917, -1.8617],\n",
              "         [ 0.0115,  1.1668, -1.6763,  1.1441,  0.7377, -1.7793],\n",
              "         [ 0.1067,  0.7168, -0.8846,  1.0514,  0.7862, -1.0022],\n",
              "         [-1.3754, -0.3129, -0.2582,  0.9532,  1.3801, -1.0791],\n",
              "         [-0.8339,  0.4875, -0.6378,  1.8469,  0.5473, -0.6652]],\n",
              "\n",
              "        [[-0.2774,  1.2891, -0.9990,  2.1361,  0.4516, -0.8229],\n",
              "         [-1.4020, -0.2505, -0.2756,  0.8289,  0.9758, -1.2685],\n",
              "         [ 0.3111,  1.2268, -0.4163,  1.4974,  0.1288, -0.3546],\n",
              "         [-0.4270,  1.6623, -1.1173,  2.6046, -0.1118, -0.8787],\n",
              "         [-1.2488, -0.3269, -0.0777,  0.3790,  0.8444, -1.0327]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "class MultiHeadedAttention(torch.nn.Module):\n",
        "    def __init__(self,heads,seq_length,dim):\n",
        "        super().__init__()\n",
        "        assert dim % heads==0\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        self.qkv_dim = heads//dim\n",
        "        self.ff = torch.nn.Linear(self.dim,self.dim,bias = False)\n",
        "        self.MHA = torch.nn.MultiheadAttention(dim,heads,batch_first=True)\n",
        "        self.o_proj = torch.nn.Linear(dim,dim,bias = False)\n",
        "        self.layernorm = torch.nn.LayerNorm([seq_length,dim])\n",
        "    def __call__(self,x,pad_mask=None,future_mask=None):\n",
        "        self.q = self.ff(x)\n",
        "        self.k = self.ff(x)\n",
        "        self.v = self.ff(x)\n",
        "        output,_ = self.MHA(self.q,self.k,self.v,key_padding_mask=pad_mask,attn_mask=future_mask)\n",
        "        print(output)\n",
        "        return self.layernorm(output)\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self,no_blocks,heads,seq_length,dim):\n",
        "        super().__init__()\n",
        "        self.no_blocks = no_blocks\n",
        "        self.MHA = MultiHeadedAttention(heads,seq_length,dim)\n",
        "        self.ff = torch.nn.Linear(dim,dim)\n",
        "    def __call__(self,x,pad_mask = None):\n",
        "        \n",
        "        for i in range(self.no_blocks):\n",
        "            output = self.MHA(x,pad_mask=pad_mask)\n",
        "            output += self.ff(x+output)\n",
        "        return output\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self,no_blocks,heads,seq_length,dim,future_mask=None):\n",
        "        super().__init__()\n",
        "        self.seq_length = seq_length\n",
        "        self.no_blocks = no_blocks\n",
        "        self.MHA = MultiHeadedAttention(heads,seq_length,dim)\n",
        "        self.ff = torch.nn.Linear(dim,dim)\n",
        "    def _create_mask(self,iteration): \n",
        "        mask = torch.ones(self.seq_length, self.seq_length)\n",
        "        mask = mask.triu_(diagonal=1 + iteration)\n",
        "        return mask\n",
        "    def __call__(self,x,future_mask=None):\n",
        "        future_mask = self._create_mask(1)\n",
        "        for i in range(self.no_blocks):\n",
        "            output = self.MHA(x,future_mask=future_mask)\n",
        "            output += self.ff(x+output)\n",
        "        return output\n",
        "    def _create_mask(self,x):\n",
        "        pass\n",
        "# class Transformer()\n",
        "x = Decoder( 1,2,5,6)(torch.normal(0,1,size = (2,5,6)))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjab6jUYrWUY",
        "outputId": "45ae4a01-a73d-40e3-a208-609e9703049b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False, False],\n",
              "        [False, False, False, False, False],\n",
              "        [ True,  True,  True,  True,  True],\n",
              "        [ True,  True,  True,  True,  True],\n",
              "        [ True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_qkt = torch.tensor([[1,1,0],[2,1,0],[1,3,0]])\n",
        "values = torch.tensor([[1,2,3,4],[4,5,6,7],[8,9,2,1]])\n",
        "torch.matmul(masked_qkt,values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrF9Z2S8ueOl",
        "outputId": "3f804445-3084-4019-e374-9a5961abcbe7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  7,  9, 11],\n",
              "        [ 6,  9, 12, 15],\n",
              "        [13, 17, 21, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "nTYzyb0d71oe",
        "outputId": "210596fe-b2bb-48e1-9a05-9981d2501e10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7de06008ced8>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-7de06008ced8>\u001b[0m in \u001b[0;36mcreate_mask\u001b[0;34m(src_input, trg_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Source input mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SRC' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sqrt(torch.tensor([1,2,3,4,5])).masked_fill(torch.tensor(  [True,True,False,False,False])   , float('-inf'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUNB7BHF-NMV",
        "outputId": "944b5b25-6bab-401b-81a3-3a591f09b6b7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -inf,   -inf, 1.7321, 2.0000, 2.2361])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.tensor([[\n",
        "    [1,2,0],\n",
        "    [3,0,5],\n",
        "    [6,0,1],\n",
        "    [0,1,2],\n",
        "],\n",
        "[\n",
        "    [1,2,0],\n",
        "    [3,0,5],\n",
        "    [6,0,1],\n",
        "    [0,1,2],\n",
        "]])\n",
        "torch.cat([k[0,:,:],k[1,:,:]],dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqvxns-H-0WK",
        "outputId": "ecf9f7cc-6ed4-4bbc-ad04-ecc01e847694"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 0, 1, 2, 0],\n",
              "        [3, 0, 5, 3, 0, 5],\n",
              "        [6, 0, 1, 6, 0, 1],\n",
              "        [0, 1, 2, 0, 1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal(0,1,size=(4,3,3,3)).masked_fill(k[:,None,None,:]==0,float('-inf')).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfRHRiS5QcYy",
        "outputId": "e32dbff7-2976-42f2-9e6a-de35ff9699d3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(torch.normal(0,1,size=(10,5,10,10)),torch.normal(0,1,size = (10,5,10,5))).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvzYQdg1QqUr",
        "outputId": "a080420f-1363-4623-812c-32cd4107cf26"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 5, 10, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1,2,3],[3,4,5]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUkw1wHLSQ45",
        "outputId": "01f4f0fb-1967-47cc-91bf-ffcab6e9a98c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1,2,3],[3,4,5]]).reshape(3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbl3gyBxT9IP",
        "outputId": "a6930485-770d-4e9b-a284-f42f7055a9fb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import MultiHeadAttention,LayerNormalization,Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "def encoder_block(input_tensor,emb_dim,num_heads):\n",
        "    q, k, v= Dense(emb_dim)(input_tensor), Dense(emb_dim)(input_tensor), Dense(emb_dim)(input_tensor)\n",
        "    output = MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim)(q,k,v)\n",
        "    output = LayerNormalization()(output)\n",
        "    res = input_tensor+output\n",
        "    output = Dense(emb_dim)(res)\n",
        "    output = output+res\n",
        "    return q,k,v,output\n",
        "input_tensor = tf.keras.layers.Input((5,12))\n",
        "output = input_tensor\n",
        "for i in range(10): \n",
        "    q,k,v, output = encoder_block(output,12,2)\n",
        "\n",
        "model = keras.Model(inputs=input_tensor, outputs=output)"
      ],
      "metadata": {
        "id": "BHmjmMaaT_Mc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = tf.random.normal((10,5,12),0,1)\n",
        "model.predict(k).shapex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te-2lbfqf0Mm",
        "outputId": "5799124b-7de3-4f75-8106-e9e08072a6bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.layers.Dense(1)(tf.random.normal((10,10,),0,1)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NYU68Lgg4cp",
        "outputId": "07d111d7-fb8a-45e6-9186-2b14d817cebe"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYmXfxSkhc-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}